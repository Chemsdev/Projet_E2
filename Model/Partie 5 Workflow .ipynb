{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORK-FLOW ULTIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = 'https://bit.ly/titanic-train-set'\n",
    "test = 'https://bit.ly/titanic-test-set'\n",
    "df_test = pd.read_csv(test, index_col=\"PassengerId\")\n",
    "df = pd.read_csv(train, index_col=\"PassengerId\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation des features & la Target\n",
    "X = df.drop('Survived', axis='columns')\n",
    "Y = df[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classement des colonnes dans des listes.\n",
    "target         =  [\"Survived\"]\n",
    "drop           =  [\"Ticket\"]\n",
    "passthrough    =  [\"Pclass\",\"SibSp\", \"Parch\"]\n",
    "text           =  [\"Name\",\"Cabin\"]\n",
    "num_manquantes =  [\"Age\",\"Fare\"]\n",
    "cat_manquantes =  [\"Embarked\"]\n",
    "cat            =  [\"Sex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste contenant toutes les colonnes\n",
    "all_cols = [\n",
    "    target,\n",
    "    drop,\n",
    "    passthrough,\n",
    "    text,\n",
    "    num_manquantes,\n",
    "    cat_manquantes,\n",
    "    cat,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification (fautes ortographes, oublie de colonnes etc...)\n",
    "def check_work(liste_all_listes):\n",
    "    set_nos_cols = set()\n",
    "    for liste in liste_all_listes:\n",
    "        for col in liste:\n",
    "            if col in set_nos_cols:\n",
    "                print(f\"Warning : La colonne '{col}' est déja présente !\")\n",
    "            set_nos_cols.add(col)         \n",
    "    set_colonnes_originales = set(df.columns)\n",
    "    mal_écrites = set_nos_cols - set_colonnes_originales\n",
    "    col_manquantes = set_colonnes_originales - set_nos_cols\n",
    "    print(f\"Des colonnes sont manquantes :  {col_manquantes}\")\n",
    "    print(f\"Des colonnes sont mal écrites : {mal_écrites}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_work(all_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer des outils pour faire le preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les utilitaires sklearn pour faire ça proprement\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gestion des colonnes catégorielles contenent des valeurs manquantes.\n",
    "cat_manquantes_preprocessing = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraire_la_premiere_lettre(serie):   \n",
    "    return pd.DataFrame(serie.str[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing de la colonne Cabin.\n",
    "preprocess_cabin = make_pipeline(\n",
    "    FunctionTransformer(extraire_la_premiere_lettre),\n",
    "    SimpleImputer(strategy='constant', fill_value=\"MANQUANTE\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\")   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Complet.\n",
    "preprocessing = make_column_transformer(\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"),  cat),\n",
    "    (cat_manquantes_preprocessing,            cat_manquantes),\n",
    "    (SimpleImputer(strategy=\"median\"),        num_manquantes),\n",
    "    (CountVectorizer(),                       'Name'), \n",
    "    (preprocess_cabin,                        'Cabin'),\n",
    "    (\"passthrough\",                           passthrough),\n",
    "    (\"drop\",                                  drop)      \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PipeLine Complète"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une Pipeline\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les Algorithmes de Machine Learning\n",
    "from sklearn.ensemble import RandomForestClassifier as RandomForest\n",
    "from sklearn.linear_model import RidgeClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Modele\n",
    "knn_pipeline = Pipeline([\n",
    "    ('Preprocessing', preprocessing),\n",
    "    ('Knn', KNN()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Ridgle Modele\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('Preprocessing', preprocessing),\n",
    "    ('Ridge', RidgeClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Modele\n",
    "forest_pipeline = Pipeline([\n",
    "    ('Preprocessing', preprocessing),\n",
    "    ('RandomForest', RandomForest()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pipeline.fit(X,Y)\n",
    "predictions_forest = forest_pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predict, vérité):\n",
    "    return (predict==vérité).mean()\n",
    "print(f\"Accuracy Random Forest : {accuracy(predictions_forest, Y)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRID SEARCH : Recherche de la Meilleure Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CrossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_folds = KFold(n_splits=5, shuffle=True, random_state=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionnaire Hyper-Paramètres Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = {}\n",
    "\n",
    "# pipeline knn\n",
    "knn[\"pipeline\"] = Pipeline([\n",
    "                            ('preprocessing', preprocessing),\n",
    "                            ('knn', KNN()),\n",
    "])\n",
    "\n",
    "# Grille pour la pipeline KNN\n",
    "knn[\"hyperparamètres\"] = {}\n",
    "knn[\"hyperparamètres\"][\"knn__n_neighbors\"]  = [1, 3, 5, 7, 9, 13, 17, 21, 27, 29]\n",
    "knn[\"hyperparamètres\"][\"knn__weights\"]      = [\"uniform\", \"distance\"]\n",
    "\n",
    "# gridsearch pour la pipeline KNN\n",
    "knn[\"gridsearch\"] = GridSearchCV(estimator  = knn[\"pipeline\"],\n",
    "                                 param_grid = knn[\"hyperparamètres\"],\n",
    "                                 scoring    = 'balanced_accuracy', \n",
    "                                 cv         = cross_validation_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn[\"gridsearch\"].fit(X, Y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn[\"gridsearch\"].best_params_;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn[\"gridsearch\"].best_score_;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PipeLine Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_final = Pipeline([\n",
    "    ('preprocessing', preprocessing), \n",
    "    ('knn', KNN(n_neighbors= 3, weights=\"distance\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement sur toutes les données\n",
    "pipeline_final.fit(X, Y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline : Les prédictions finales\n",
    "predict = pipeline_final.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Workflow_Ultime_2_(code).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
