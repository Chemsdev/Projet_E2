{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5388da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.impute import KNNImputer\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, QuantileTransformer\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22d780cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des modèles à utiliser.\n",
    "models = {\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(),\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'Support Vector Machine': SVR()\n",
    "}\n",
    "\n",
    "# Paramètres à rechercher pour chaque modèle.\n",
    "param_grid = {\n",
    "    'Ridge': {\n",
    "        'alpha': [0.1, 1.0, 10.0],\n",
    "        'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "    },\n",
    "    'Lasso': {\n",
    "        'alpha': [0.1, 1.0, 10.0],\n",
    "        'max_iter': [1000, 2000, 3000],\n",
    "        'selection': ['cyclic', 'random']\n",
    "    },\n",
    "    'Linear Regression': {\n",
    "        'fit_intercept': [True, False],\n",
    "        'copy_X': [True, False]\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 4, 5]\n",
    "    },\n",
    "    'Support Vector Machine': {\n",
    "        'C': [0.1, 1.0, 10.0],\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'epsilon': [0.1, 0.2, 0.5]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7485469e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import de la Data.\n",
    "data = pd.read_csv(\"data/Housing_Price.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72eb084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Supression de la colonne gender.\n",
    "# 2) Remplaçement des \"no\" par des \"nan\" pour faciliter l'imputation.\n",
    "# 3) Encodage de la variable catégorielle \"ocean_proximity\"\n",
    "# 4) bool : imputation des données.\n",
    "def preprocessing(data, imputing:bool):\n",
    "    \n",
    "    # Nettoyage : Encodage, conversion des colonnes.     \n",
    "    if \"gender\" in data.columns:\n",
    "        data.drop(\"gender\", axis=1,inplace=True)\n",
    "    if \"households\" in data.columns:\n",
    "        data['households'].replace(\"no\", np.nan , inplace=True)\n",
    "        data[\"households\"] = data[\"households\"].astype('float64')\n",
    "    if \"ocean_proximity\" in data.columns:\n",
    "        data = pd.get_dummies(data, columns=['ocean_proximity'], prefix=[\"\"])\n",
    "    \n",
    "    # Imputing des données.     \n",
    "    if imputing:\n",
    "        knn_imputer = KNNImputer(n_neighbors=2)  \n",
    "        imputed_data = knn_imputer.fit_transform(data)\n",
    "        imputed_df = pd.DataFrame(imputed_data, columns=data.columns)\n",
    "        \n",
    "        # On retourne le Dataframe avec données manquantes imputées.         \n",
    "        return imputed_df\n",
    "    \n",
    "    # On retourne le Dataframe avec données manquantes non imputées.         \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a43c5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Réalisation d'un GridSearch à partir des dictionnaires définis plus haut.\n",
    "def grid_search_regression(X, y, param_grid_dict:dict, models_dict:dict):\n",
    "    \n",
    "    # Dictionnaires pour enregistrer les meilleurs models et les meilleurs paramètres.     \n",
    "    best_models = {}\n",
    "    best_params = {}\n",
    "    \n",
    "    # Exécution des models avec les paramètres.\n",
    "    for model_name, model in models.items():\n",
    "        grid_search = GridSearchCV(model, param_grid[model_name], cv=5, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X, y)\n",
    "        best_models[model_name] = grid_search.best_estimator_\n",
    "        best_params[model_name] = grid_search.best_params_\n",
    "    \n",
    "    # On retourne les meilleurs model & les meilleurs paramètres de chaque model.     \n",
    "    return best_models, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aeabe918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Séparation des données X et Y.\n",
    "# 2) bool : Scaling des données.\n",
    "# 3) TrainTestSplit des données.\n",
    "# 4) bool : GridSearch.\n",
    "def model(preprocess_data, gridsearching:bool, scaling:bool, param_grid_dict:dict, models_dict:dict):\n",
    "    \n",
    "    \n",
    "    # --------------  Scaling & TraintTestSplit --------------- #\n",
    "    #===========================================================>    \n",
    "    \n",
    "    # Séparation X et Y.\n",
    "    X = preprocess_data.drop(\"median_house_value\", axis=1)\n",
    "    Y = preprocess_data[\"median_house_value\"]\n",
    "    \n",
    "    # bool : Scaling des données.     \n",
    "    if scaling:\n",
    "        scaler = MinMaxScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "    # Modeling : Régression Linéaire.\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # --------------  Modelling whit GridSearch --------------- #\n",
    "    #===========================================================>     \n",
    "    \n",
    "    # bool : GridSearch.     \n",
    "    if gridsearching:\n",
    "        best_models, best_params = grid_search_regression(X_train, Y_train, param_grid_dict, models_dict)\n",
    "        score_models_with_gridsearch = {}\n",
    "        for model_name, model in best_models.items():\n",
    "            y_pred = model.predict(X_test)\n",
    "            score = r2_score(Y_test, y_pred)\n",
    "            score_models_with_gridsearch[model_name] = score\n",
    "\n",
    "        results_list = []\n",
    "        for model_name, score in score_models_with_gridsearch.items():\n",
    "            \n",
    "            # Récupération des scores de chaque model.             \n",
    "            results_list.append({\n",
    "                \"Modèle\"   : model_name,\n",
    "                \"Score R2\" : score\n",
    "            })\n",
    "        \n",
    "        # Création d'un DataFrame contenant les scores & nom de chaque model.         \n",
    "        results_df = pd.DataFrame(results_list)\n",
    "        \n",
    "        # Ajout de la colonne 'Meilleurs Paramètres' avec le dictionnaire best_params.\n",
    "        results_df = results_df.assign(**{\"Meilleurs Paramètres\": best_params.values()})\n",
    "        return results_df\n",
    "    \n",
    "    \n",
    "    # ------------  Modelling whitout GridSearch -------------- #\n",
    "    #===========================================================> \n",
    "    \n",
    "    # dictionnaire withs scores & name models.     \n",
    "    score_models_without_gridsearch = {}\n",
    "    for model in models_dict.values():\n",
    "        model.fit(X_train, Y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        score = r2_score(Y_test, y_pred)\n",
    "        score_models_without_gridsearch[type(model).__name__] = score\n",
    "    \n",
    "    results_df = pd.DataFrame.from_dict(score_models_without_gridsearch, orient='index', columns=['R2 Score'])\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4dd0883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Preprocessing.\n",
    "preprocess_data = preprocessing(\n",
    "    data     = data,\n",
    "    imputing = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455e7d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Modelling.\n",
    "results_df = model(\n",
    "    preprocess_data = preprocess_data, \n",
    "    gridsearching   = True,\n",
    "    scaling         = True,\n",
    "    param_grid_dict = param_grid, \n",
    "    models_dict     = models\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2e6133",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
